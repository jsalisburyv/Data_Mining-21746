---
title: "Final Project - Data Mining"
author: 
  - Dawid Michal Roch Móll 
  - Jonathan Zinzan Salisbury Vega
  - Joan Sansó Pericàs
  - Joan Vilella Candia
  - Julián Wallis Medina
date: 01/02/2023
output:
  html_document:
    toc: true
    toc_depth: 3
    css: doc.css
editor_options:
  markdown:
    wrap: 80
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r message=FALSE, warning=FALSE}
# Import necessary libraries
library(ggplot2)
library(grid)
library(gridExtra)
library(Rmisc)
library(dplyr)
library(ggdist)
library(caret)
library(tidyverse)
library(plotly)
library(networkD3)
library(scales)
library(reshape)
library(klaR)
library(countrycode)
library(ISLR)
library(rpart)
library(rpart.plot)


set.seed(999)
```

# Part 1: Data Analysis

## Raw Data

Let's take a look into our raw data. 
We have 1332 data entries with 11 variables. 
```{r}
df <- read.csv("salaries.csv", stringsAsFactors = TRUE)
summary(df)
str(df)
```

## Pre-processing

During our pre-processing we're going to look for NA values, outliers, transform and create some variables and do some initial data visualization.

### NA values

We don't have any NA values so we don't have to worry about it
```{r}
anyNA(df)
```

### Outliers

We have decided to not delete any data entries that might be considered as outliers, as they may represent genuine variations in the population's distribution.

### Feature Engineering

We've decided to delete the salary variable since we already have salary_in_usd which allows us to do better comparisons.

We've also changed the remote_ration from 0, 50 and 100 to Office, Hybrid and Remote.

We've created the variable salary_group.
```{r}
df$salary <- NULL

df$remote_ratio <- as.factor(df$remote_ratio)
levels(df$remote_ratio) <- list("Office" = 0, "Hybrid" = 50,  "Remote" = 100)

df$salary_group <- cut(df$salary_in_usd, c(0, 25000, 50000, 75000, 100000, 125000, 150000, 200000, 250000, 1000000))
df$salary_group <- as.factor(df$salary_group)
levels(df$salary_group) <- c("25k", "50k", "75k", "100k", "125k", "150k", "200k", "250k", "1M")
```

The variables employee_residence and company_location have too many levels (64 and 59)
Because of this we've decided to create two new variables: employee_region and company_region where we've grouped the countries into the 7 continets
```{r}
northAmerica <-c("US", "CA", "MX")
southAmerica <- c("AR", "BO", "BR", "CL", "CO")
centralAmerica <- c("CR", "DO", "HN", "PR")
europe <- c("AL", "AT", "AX", "BE", "BG", "CH", "CZ", "DE", "DK", "EE", "ES", "FI", "FR", "GB", "GR", "HR", "HU", "IE", "IS", "IT", "JE", "LU", "MD", "MT", "NL", "PL", "PT", "RO", "RS", "RU", "SI", "TR", "UA")
asia <- c("AE", "CN", "HK", "ID", "IL", "IN", "IQ", "IR", "JP", "MY", "PH", "PK", "QA", "SG", "TH", "VN")
africa <- c("DZ", "EG", "KE", "NG", "TN", "TZ")
oceania <- c("AU", "NZ", "AS")

df$employee_region <- as.factor(df$employee_residence)
levels(df$employee_region) <- list(  
  "North America" = northAmerica,   
  "South America" = southAmerica,   
  "Central America" = centralAmerica,
  "Europe" = europe,
  "Asia" = asia,   
  "Africa" = africa, 
  "Oceania" = oceania)

df$company_region <- as.factor(df$company_location)
levels(df$company_region) <- list(  
  "North America" = northAmerica,   
  "South America" = southAmerica,   
  "Central America" = centralAmerica,
  "Europe" = europe,
  "Asia" = asia,   
  "Africa" = africa, 
  "Oceania" = oceania)
```


Our dataset has 64 different job titles. This is a problem because there are job titles that are more related between each other than others. Per example: Machine Learning Engineer with Machine Learning Research rather than with Data Manager

This is why we've created 4 new variables based on the job title:

* Industry: DATA, AI/ML and OTHER
* Role: SCIENTIST, ENGINEER, ANALYST, MANAGER, ARCHITECT and DEVELOPER
* Boss: TRUE and FALSE
* Research: TRUE and FALSE

```{r}
df$job_title[df$job_title == "ML Engineer"] <- "Machine Learning Engineer"

df$industry <- ifelse( grepl("data", df$job_title, ignore.case = T), "DATA", "OTHER")
df$industry <- ifelse(grepl("machine", df$job_title, ignore.case = T), "ML/AI", df$industry)
df$industry <- ifelse( grepl("AI", df$job_title, ignore.case = T), "ML/AI", df$industry)
df$industry <- as.factor(df$industry)

df$role <- ifelse(grepl("scientist", df$job_title, ignore.case = T), "SCIENTIST", "OTHER")
df$role <- ifelse(grepl("engineer", df$job_title, ignore.case = T), "ENGINEER", df$role)
df$role <- ifelse(grepl("analyst", df$job_title, ignore.case = T), "ANALYST", df$role)
df$role <- ifelse(grepl("manager", df$job_title, ignore.case = T), "MANAGER", df$role)
df$role <- ifelse(grepl("architect", df$job_title, ignore.case = T), "ARCHITECT", df$role)
df$role <- ifelse(grepl("developer", df$job_title, ignore.case = T), "DEVELOPER", df$role)
df$role <- as.factor(df$role)

df$boss <- ifelse(grepl("head", df$job_title, ignore.case = T), TRUE, FALSE)
df$boss <- ifelse(grepl("lead", df$job_title, ignore.case = T), TRUE, df$boss)
df$boss <- ifelse(grepl("principal", df$job_title, ignore.case = T), TRUE, df$boss)
df$boss <- ifelse(grepl("director", df$job_title, ignore.case = T), TRUE, df$boss)

df$research <- ifelse(grepl("research", df$job_title, ignore.case = T), TRUE, FALSE)

```
### Data Visualization

First we will plot the distribution of some of our variables (we haven't ploted the location or currency because they have to many levels)
```{r message=FALSE, warning=FALSE}
ggplot(df, aes_string(x="salary_in_usd")) +
    ggdist::stat_halfeye(
      adjust=0.5,
      justification = -.2,
      .width=0
    ) +
    geom_boxplot(
      width = .1,
      alpha = 0.5
    ) +
     labs(title="Distribution and boxplot of salary_in_usd", y="count")

factors_names <- c("work_year", "experience_level", "employment_type", "remote_ratio", "company_size", "company_region", "employee_region", "salary_group", "industry", "role")
for (i in 1:length(factors_names)){
  print(ggplot(df, aes_string(x= factors_names[i])) +
    geom_bar()+
     labs(title=paste("Histogram of",factors_names[i]),y="count"))
}

```

In these boxplots we can see that the salary may be conditioned by some attributes. Per example entry level employees earn less than executives
```{r}
par(mfrow = c(2,2))
p1 <- plot(df$role, df$salary_in_usd, xlab="Role", ylab="Salary in USD")
p2 <- plot(df$experience_level, df$salary_in_usd, xlab="Experience Level", ylab="Salary in USD")
p3 <- plot(df$remote_ratio, df$salary_in_usd, xlab="Remote Ratio", ylab="Salary in USD")
p4 <- plot(as.factor(df$boss), df$salary_in_usd, xlab="Boss", ylab="Salary in USD")
```
In this Sankey Diagram we can see the amount of people that live in a region and work for another region
```{r}
aux <- data.frame(matrix(0, nrow = length(levels(df$company_region)), ncol = length(levels(df$company_region))))
colnames(aux) <- levels(df$company_region)
rownames(aux) <- levels(df$company_region)

for (i in 1:nrow(aux)) {
  for (j in 1:ncol(aux)) {
    aux[i, j] <- length(which(df$company_region == colnames(aux)[j] & df$employee_region == rownames(aux)[i]))
  }
}

data_long <- aux %>%
  rownames_to_column %>%
  gather(key = 'key', value = 'value', -rowname) %>%
  filter(value > 0)
colnames(data_long) <- c("source", "target", "value")
data_long$target <- paste(data_long$target, " ", sep="")

nodes <- data.frame(name=c(as.character(data_long$source), as.character(data_long$target)) %>% unique())
 
data_long$IDsource=match(data_long$source, nodes$name)-1 
data_long$IDtarget=match(data_long$target, nodes$name)-1

sankeyNetwork(Links = data_long, Nodes = nodes,
                     Source = "IDsource", Target = "IDtarget",
                     Value = "value", NodeID = "name", 
                     sinksRight=FALSE, nodeWidth=30, fontSize=14, nodePadding=15)

```

In this graph we can see that from the year 2021 to 2022 people stopped working Hybrid and they went to work from home or to the office.
```{r}
y_2020 <- df[df$work_year == 2020,]
y_2021 <- df[df$work_year == 2021,]
y_2022 <- df[df$work_year == 2022,]

y_2020 <- y_2020 %>% group_by(remote_ratio) %>% summarise(count = n())
y_2021 <- y_2021 %>% group_by(remote_ratio) %>% summarise(count = n())
y_2022 <- y_2022 %>% group_by(remote_ratio) %>% summarise(count = n())

y_2020$percentage <- y_2020$count / sum(y_2020$count) * 100
y_2021$percentage <- y_2021$count / sum(y_2021$count) * 100
y_2022$percentage <- y_2022$count / sum(y_2022$count) * 100

y_2020$work_year <- 2020
y_2021$work_year <- 2021
y_2022$work_year <- 2022

y <- rbind(y_2020, y_2021, y_2022)

ggplot(y, aes(x = work_year, y = percentage, group = remote_ratio, color = remote_ratio)) +
  geom_line()+
  geom_point() + 
  labs(x = "Work Year", y = "Percentage of Remote Ratio", title = "Remote Ratio by Work Year") +
  theme(plot.title = element_text(hjust = 0.5), axis.text=element_text(size=12),
        axis.title=element_text(size=12)) +
  scale_x_continuous(breaks = c(2020, 2021, 2022))


```

# Part 2: Context of the problem, Models and Evaluation

## Research Questions

### 1. Profile-based prediction and maximization of compensation

```{r}
#First we remove some columns that wont bring useful information to the model:

dfTreeRegression <- df
dfTreeRegression$salary_currency <- NULL

#We are going to try to predict salary with a regression tree. We are going to eliminate the created "salary_group" column because otherwise it would be kinda cheating since its the value that we are trying to predict.

dfTreeRegression$salary_group <- NULL

#After making a couple of tests, we saw that these variables are never used by the tree to make predictions, so we are going to remove them from the set so getting the best options for our profiles is easier later:

dfTreeRegression$company_region <- NULL
dfTreeRegression$employee_region <- NULL
dfTreeRegression$work_year <- NULL
dfTreeRegression$research <- NULL
dfTreeRegression$employment_type <- NULL
dfTreeRegression$role <- NULL
dfTreeRegression$boss <- NULL

set.seed(42)
sample <- sample(c(TRUE, FALSE), nrow(dfTreeRegression), replace=TRUE, prob=c(0.8,0.2))
Tree_train  <- dfTreeRegression[sample, ]
Tree_test   <- dfTreeRegression[!sample, ]

```

#### 1.1 Model
```{r}
#Con el parametro "cp", cuanto mas proximo a 0, menos poda hace.
fit <- rpart(salary_in_usd~., data = Tree_train, method="anova", control = list(cp = 0.0001))
rules <- rpart.rules(fit)

test_pred <- predict(fit, Tree_test, method="anova")
results <- data.frame(test_pred, Tree_test$salary_in_usd)
results$residuals <- results$Tree_test.salary_in_usd-results$test_pred
plot(results$residuals)
abline(0,0, col="red")
resmean <- mean(results$residuals)
abline(resmean,0, col="blue")
sd(results$residuals)
nrow(rules)
```
#### 1.2 Salary Prediction
```{r}
datos_monica <- Tree_test[1,]
datos_monica[1,] = list("MI", "Data Scientist",0, "ES", "Hybrid", "ES", "S", "DATA")
options(width=1000)

salarios = rpart.predict(fit, datos_monica)
salarios
```

#### 1.3 Salary Maximization
```{r}
wallis_grid <- expand.grid(
  experience_level = c("EN"),
  job_title = c("ML Engineer"),
  salary_in_usd = 0,
  employee_residence = c("US"),
  remote_ratio = levels(df$remote_ratio),
  company_location = c("US"),
  company_size = levels(df$company_size),
  industry = c("ML/AI")
)
head(wallis_grid)
```

```{r}
prediction <- rpart.predict(fit, wallis_grid)
wallis_max <- max(prediction)
wallis_best_combinations_index <- which(wallis_max == prediction)
wallis_best_combinations <- wallis_grid[wallis_best_combinations_index,]
wallis_best_combinations
wallis_max
```

```{r}
dawid_grid <- expand.grid(
  experience_level = c("MI"),
  job_title = c("ML Engineer"),
  salary_in_usd = 0,
  employee_residence = c("ES"),
  remote_ratio = c("Remote"),
  company_location = levels(df$company_location),
  company_size = levels(df$company_size),
  industry = c("ML/AI")
)
head(dawid_grid)
```

```{r}
prediction <- rpart.predict(fit, dawid_grid)
dawid_max <- max(prediction)
dawid_best_combinations_index <- which(dawid_max == prediction)
dawid_best_combinations <- dawid_grid[dawid_best_combinations_index,]
dawid_best_combinations
dawid_max
```



### 2. How can data mining techniques be used to identify which employees are at risk of leaving their company?

This could be useful for companies who want to retain their top talent and for employees that are underpaid. We could use different factors such to determine which employees are underpaid compared to their peers.

To answer this questions we will use two different techniques: Clustering and regression.

The following features will be used:

* Experience level
* Employment type
* Industry
* Employee region
* Company region
* Role
* Remote_ratio
* Boss
* Research
* Company size

#### 2.1 Clustering

First we create a separate dataframe for the variables we will use.
```{r}
# Select the variables to use in the clustering analysis
df_vars <- dplyr::select(df, experience_level, employment_type, company_size, industry, employee_region, company_region, boss, research, role, remote_ratio)
```

Lets find find the elbow in our plot, to find the "best" k for the kmodes algorithm
```{r}
results <- data.frame(k = integer(), WCSS = double())

# Loop through a range of values for k
for (k in 2:30) {
  # Run the k-means clustering algorithm
  km <- kmodes(df_vars, k, iter.max = 25)
  # Store the results in the data frame
  results <- rbind(results, data.frame(k = k, WCSS = sum(km$withindiff^2)))
}

# Plot the WCSS values for each value of k
ggplot(results, aes(x = k, y = WCSS)) +
  geom_line() +
  geom_point() +
  labs(x = "Number of clusters (k)", y = "WCSS")
```


```{r}
# Perform k-means clustering with n clusters
kmodes_results <- kmodes(df_vars, 20)

df_Q7 <- df

# Add the cluster labels to the original data
df_Q7$cluster <- kmodes_results$cluster

group_by(df_Q7, cluster) %>%
  summarize(mean_salary = mean(salary_in_usd))

mean_salary <- tapply(df_Q7$salary_in_usd, df_Q7$cluster, mean)

# Calculate the difference between the real salary and the mean salary of the cluster that the employee pertains to
df_Q7$salary_difference_kmodes <- 0
df_Q7$predicted_salary_kmodes <-0

for (i in 1:nrow(df_Q7)) {
  cluster_index = match(df_Q7$cluster[i], names(mean_salary))
  df_Q7$salary_difference_kmodes[i] <- df_Q7$salary_in_usd[i] - mean_salary[cluster_index]
  df_Q7$predicted_salary_kmodes[i] <- mean_salary[cluster_index]
}
```

#### 2.2 Multi Lineal Regression

The lineal model that we will use is quite simple, with out using combination of variables we will stick to a base model.
```{r}
model <- lm(salary_in_usd ~ experience_level + employment_type + employee_region + company_size + industry + role + boss + research + remote_ratio + company_region, data = df_Q7)
summary(model)
```

```{r}
df_Q7$predicted_salary_lm  <- predict(model, newdata = df_Q7)
df_Q7$salary_difference_lm <- df_Q7$salary_in_usd - df_Q7$predicted_salary_lm
```

#### 2.3 Results

Once we have the salary difference between the predicted salary using both methods we will calculate the percentage error. 

Then we will partition the data entries into 3 groups depending on the error of the prediction. Underpaid, Normal and Overpaid

```{r}
df_Q7$kmodes_ratio_error <- ((df_Q7$predicted_salary_kmodes / df_Q7$salary_in_usd)-1)*100
df_Q7$lm_ratio_error <- ((df_Q7$predicted_salary_lm / df_Q7$salary_in_usd)-1)*100

summary(df_Q7[, c("kmodes_ratio_error","lm_ratio_error")])
quantiles_kmodes <- quantile(df_Q7$kmodes_ratio_error, c(0.25,0.75))
quantiles_lm <- quantile(df_Q7$lm_ratio_error, c(0.25,0.75))

```

```{r}
df_Q7 <- df_Q7[order(df_Q7$salary_in_usd),]
x <- 1:nrow(df_Q7)

df_Q7$status_lm <- ifelse(df_Q7$lm_ratio_error < quantiles_kmodes[1], "Overpaid", 
                      ifelse(df_Q7$lm_ratio_error < quantiles_kmodes[2], "Normal", "Underpaid"))

df_Q7$status_kmodes <- ifelse(df_Q7$kmodes_ratio_error < quantiles_lm[1], "Overpaid", 
                      ifelse(df_Q7$kmodes_ratio_error < quantiles_lm[2], "Normal", "Underpaid"))
```


Once we have this three groups we can plot the predicted salary versus the real salary using.
We've colored the predicted salary depening on the consideration.
```{r}
ggplot(df_Q7, aes(x = x, y = salary_in_usd)) +
        geom_point(aes(y = salary_in_usd), size= 2, shape = 20) +
        geom_point(aes(y = predicted_salary_lm, color = status_lm), size =2,  shape = 20, alpha = 0.9) + 
        scale_color_manual(
          values = c("Overpaid" = "red", "Underpaid" = "orange", "Normal" = "green"), 
          labels = c('Normal', 'Overpaid', 'Underpaid'),
          aesthetics = c("colour", "fill"), 
          name = "Consideration") +
        ggtitle("Plot of salary and predicted salaries using Linear Regression") +
        ylab("Salary in USD") +
        scale_y_continuous(labels = label_comma(), breaks = scales::pretty_breaks(n = 10))
        

ggplot(df_Q7, aes(x = x, y = salary_in_usd)) +
        geom_point(aes(y = salary_in_usd), size= 2, shape = 20) +
        geom_point(aes(y = predicted_salary_kmodes, color = status_kmodes), size =2,  shape = 20, alpha = 0.9) + 
        scale_color_manual(
          values = c("Overpaid" = "red", "Underpaid" = "orange", "Normal" = "green"), 
          labels = c('Normal', 'Overpaid', 'Underpaid'),
          aesthetics = c("colour", "fill"),
          name = "Consideration") +
        ggtitle("Plot of salary and predicted salaries using Clustering") +
        ylab("Salary in USD") +
        labs(fill="Consideration") +
        scale_y_continuous(labels = label_comma(), breaks = scales::pretty_breaks(n = 10))


```


In this heatmap we can see the difference between the consideration of both models. As we see they mostly 
"agree" with each other
```{r warning=FALSE}
df_Q7$status_lm <- as.factor(df_Q7$status_lm)
df_Q7$status_kmodes <- as.factor(df_Q7$status_kmodes)

ct <- table(df_Q7$status_lm,df_Q7$status_kmodes)
ct <- ct[c(3,1,2),c(3,1,2)]
ct <- melt(ct)
colnames(ct) <- c("LinearRegression", "Clustering", "Count")

ggplot(ct, aes(x = LinearRegression, y = Clustering, fill = Count)) +
  geom_tile() +
  scale_fill_gradient2(low = "#075AFF", mid = "#FFFFCC", high = "#FF0000") +
  geom_text(aes(label = Count), color = "black", size = 4) +
  coord_fixed() +
  ggtitle("Comparison between Clustering and Linear Regression") 

```

```{r}
underpaid_lm <- df_Q7[df_Q7$status_lm=="Underpaid",]
overpaid_lm <- df_Q7[df_Q7$status_lm=="Overpaid",]

underpaid_kmodes <- df_Q7[df_Q7$status_kmodes =="Underpaid",]
overpaid_kmodes  <- df_Q7[df_Q7$status_kmodes =="Overpaid",]
```

In this graph we can see the different distribution of the experience level and role attributes amongst the three "fairness" consideration.

```{r message=FALSE, warning=FALSE}
variables <- c("experience_level", "role")

for (i in 1:length(variables)){
  ratio_df <- table(df_Q7[, c(variables[i])])/nrow(df_Q7)
  ratio_up_lm <- table(underpaid_lm[, c(variables[i])])/nrow(underpaid_lm)
  ratio_op_lm <- table(overpaid_lm[, c(variables[i])])/nrow(overpaid_lm)

  # plot them in such a way that they can be compared
  df_long_lm <- melt(data.frame(ratio_up_lm, ratio_df, ratio_op_lm))
  
  ratio_up_kmodes <- table(underpaid_kmodes[, c(variables[i])])/nrow(underpaid_kmodes)
  ratio_op_kmodes <- table(overpaid_kmodes[, c(variables[i])])/nrow(overpaid_kmodes)

  # plot them in such a way that they can be compared
  df_long_kmodes <- melt(data.frame(ratio_up_kmodes, ratio_df, ratio_op_kmodes))

  print(ggplot(data = df_long_lm, aes(x = variable, y = value , fill = Var1, label = round(value, 2))) +
    geom_bar(stat = "identity", position = "fill") +
    geom_text(size = 3, position = position_stack(vjust = 0.5)) +
    scale_x_discrete(labels = c("Freq"= "Underpaid", "Freq.1"= "Normal", "Freq.2" = "Overpaid")) +
    labs(fill=variables[i], title=paste("Stacked percent bar chart of ",variables[i], " (LM)"), x="Consideration", y = "%"))
  
   print(ggplot(data = df_long_kmodes, aes(x = variable, y = value , fill = Var1, label = round(value, 2))) +
    geom_bar(stat = "identity", position = "fill") +
    geom_text(size = 3, position = position_stack(vjust = 0.5)) +
    scale_x_discrete(labels = c("Freq"= "Underpaid", "Freq.1"= "Normal", "Freq.2" = "Overpaid")) +
    labs(fill=variables[i], title=paste("Stacked percent bar chart of ",variables[i], " (Clustering)"), x="Consideration", y = "%"))
}

```

Entry level employees represent the 23% of the underpaid while only being an 11% and 7% in the normal and overpaid. On the other hand, Executives and Senior employees are respectively 1% and 42% in the underpaid category, 3% and 60% in the normal category and 7% and 64% in the overpaid category. This can help us see that entry level employees might be underpaid compared to their peers (members of its own cluster) while senior and executive might be overpaid. 
By this we don’t mean that the salaries aren’t fair but we show that amongst people with similar attributes entry level employees tend to earn less while seniors and executives tend to earn more

### 3. Employee Seniority: Upward mobility and career growth

#### 3.1 Decision Tree

Can we predict an employee's experience level based on their salary and job title? Using classification algorithms, we could build a model that predicts an employee's experience level based on their salary and job title. This could be useful for employees and job seekers who want to understand what experience level they can expect to be paid for a given salary and job title. We could also include other factors, such as location and company size, to improve the accuracy of the model.

For this we'll use a Decision Tree since we are interested in having a clear way to visualize and understand the result. We want to classify the experience level of employees based on attributes such as their role, industry for which they work, salary, etcetera.

BASE MODEL: Predict experience level with only salary and job title; since job title is a factor with numerous levels industry and role will be used instead.

```{r}
df14 = df[, c("industry", "role", "salary_in_usd", "experience_level")]
dt14 = rpart(experience_level~., data=df14)
rpart.plot(dt14)
```

ADVANCED MODEL: Predict experience level with all of the variables available (apart from those which factor level exceeds 32).

```{r}
df14v2 = df[ , -which(names(df) %in% c("job_title", "work_year", "ID", "company_location", "employee_residence", "employee_region", "company_region", "salary_group", "salary_currency", "remote_ratio"))]
summary(df14v2)
dt14v2 = rpart(experience_level~., data=df14v2)
rpart.plot(dt14v2)
```


#### 3.2 K-NN

How accurately can we predict experience_level within the company using a k-nearest neighbors classification model, while excluding the salary attribute from the dataset?

we first create a dataset without the salary variables, and partition it into a 70% train and test subset.

```{r}
set.seed(123)
df_no_s <- df
df_no_s$salary_group <- NULL
df_no_s$salary_currency <- NULL
df_no_s$salary_in_usd <- NULL
train_index <- createDataPartition(df_no_s$experience_level, p = 0.7, list = FALSE)
train_data <- df_no_s[train_index, ]
test_data <- df_no_s[-train_index, ]

```

We then create and train the knn model, with k's from 1 to 20.

```{r}
model <- train(experience_level ~ ., data = train_data, method = "knn", tuneGrid = expand.grid(k = 1:20))

```

```{r}
print(model$bestTune$k)
summary(model)
```
As we can see the best results where obtained when k=1. Now we can proceed to check which variables are more important in the model to determine the experience level.

```{r}
importance <- varImp(model)
plot(importance)

```

  As shown in the plot above, the variables vary depending on each experience level, but the most influential ones are the employee and company locations, work_year and boss.  
We can now check the metrics of the model to see how good it performs when predicting the test subset.

```{r}
predictions <- predict(model, test_data)
cMatrix <- confusionMatrix(predictions, test_data$experience_level)
```
The overall accuracy of the model is 73% which is acceptable but could be better. We can also check in the confusion matrix the prediction vs reference and the statistics by each class of experience level. Overall, the model's performance is good, but it may be worth exploring other models or techniques to improve its accuracy and robustness.


## Discarded Questions

### 1. How much should the salary increase be when you get promoted to a higher Experience Level?

This could be useful for employees that are going to recieve a promotion, and want
to know how much they should get paid for their new position.
It could also be useful for employers that want to know how much they should offer
new hires or promoting employees.

```{r}
f <- ggplot(df, aes(x=reorder(experience_level,salary_in_usd), y=salary_in_usd))+
     geom_boxplot()+
     ggtitle("Salary Distribution for each experience level") + ylab("Salary (USD)") + xlab("")
f
```
As we can see, from ENtry level to EXecutive level, as the experience increases, the larger the average salary gets. Lets see if we can find, using clustering, 3 zones for each


```{r message=FALSE, warning=FALSE, include=FALSE}
set.seed(42)
df_split_industry <- split(df, df$industry)
names(df_split_industry) <- c("df_data", "df_ai", "df_other")
list2env(df_split_industry, envir = .GlobalEnv)

get_average_level_salary <- function(dFrame){
  mean_en = mean(dFrame[dFrame$experience_level=="EN","salary_in_usd"])
  mean_mi = mean(dFrame[dFrame$experience_level=="MI","salary_in_usd"])
  mean_se = mean(dFrame[dFrame$experience_level=="SE","salary_in_usd"])
  mean_ex = mean(dFrame[dFrame$experience_level=="EX","salary_in_usd"])
  ret = data.frame(c("EN","MI","SE","EX"),c(mean_en, mean_mi, mean_se, mean_ex))
  colnames(ret) <- c("Experience_Level","Average_Salary")
  ret$Experience_Level = factor(ret$Experience_Level, levels = c("EN","MI","SE","EX"))
  return(ret)
}

data_avg = get_average_level_salary(df_data)
ai_avg = get_average_level_salary(df_ai)
other_avg = get_average_level_salary(df_other)
```

```{r}

custom_line_plot <- function(datos,avgs, title){
  plot1 <- ggplot()+
            geom_violin(data=datos, aes(x=reorder(experience_level,salary_in_usd), y = salary_in_usd))+ 
  geom_line(data=avgs,aes(x=Experience_Level, y=Average_Salary, group=1))+
  geom_point(data=avgs,aes(x=Experience_Level, y=Average_Salary, group=1))+
  geom_text(data=avgs,aes(x=Experience_Level, y=Average_Salary, label = round(Average_Salary,0)) ,hjust=-0.2, vjust=-1)+
  scale_y_continuous(breaks = scales::pretty_breaks(n = 15))+
  labs(title=title)
  plot1
}

custom_line_plot(df_data,data_avg,"Data Industry")
custom_line_plot(df_ai,ai_avg,"AI/ML Industry")
custom_line_plot(df_other, other_avg,"Other Industries")

```

```{r}
get_increases <- function(dframe){
  dframe$increase <- 0
dframe$increase[dframe$Experience_Level=="MI"] <- dframe$Average_Salary[dframe$Experience_Level=="MI"] - dframe$Average_Salary[dframe$Experience_Level=="EN"]
dframe$increase[dframe$Experience_Level=="SE"] <- dframe$Average_Salary[dframe$Experience_Level=="SE"] - dframe$Average_Salary[dframe$Experience_Level=="MI"]
dframe$increase[dframe$Experience_Level=="EX"] <- dframe$Average_Salary[dframe$Experience_Level=="EX"] - dframe$Average_Salary[dframe$Experience_Level=="SE"]

dframe$increasePercentage <- 0
dframe$increasePercentage[dframe$Experience_Level=="MI"] <- dframe$Average_Salary[dframe$Experience_Level=="MI"] / dframe$Average_Salary[dframe$Experience_Level=="EN"]
dframe$increasePercentage[dframe$Experience_Level=="SE"] <- dframe$Average_Salary[dframe$Experience_Level=="SE"] / dframe$Average_Salary[dframe$Experience_Level=="MI"]
dframe$increasePercentage[dframe$Experience_Level=="EX"] <- dframe$Average_Salary[dframe$Experience_Level=="EX"] / dframe$Average_Salary[dframe$Experience_Level=="SE"]

dframe$increasePercentage <- ifelse(dframe$Experience_Level=="EN",0,(dframe$increasePercentage - 1) * 100)

return(dframe)
}

data_avg <- get_increases(data_avg)
ai_avg <- get_increases(ai_avg)
other_avg <- get_increases(other_avg)

data_avg
ai_avg
other_avg
```

 


### 2. What is more worth, to work in the office at your region or remotely in another region?

First we should have a look at how much are employees paid while working in the office at their same region.

```{r}
df_filtered <- filter(df, employee_region == company_region)

print(ggplot(aes(x = employee_region, y = salary_in_usd, fill=employee_region), data = df_filtered) +
    stat_summary(fun=mean, geom="bar", position = "stack") +
    stat_summary(aes(label=round(after_stat(y),2)), fun.y=mean, geom="text", size=3, vjust = -0.5) + 
    xlab("Region") + labs(title="Salary of any work in the same Region"))
```

Here we can see that most of the Regions are underpaid for office work compared to North America, especially the rest of america.

Could they earn more if they work remotely for another Region?

Lets have a look at how much do companies in each region pay for Remote work.


```{r}
df_filtered <- filter(df, employee_region != company_region & remote_ratio == "Remote")

print(ggplot(aes(x = company_region, y = salary_in_usd, fill=company_region), data = df_filtered) +
    stat_summary(fun=mean, geom="bar", position = "stack") +
    stat_summary(aes(label=round(after_stat(y),2)), fun.y=mean, geom="text", size=3, vjust = -0.5) + 
    xlab("Region") + labs(title="Salary of Remote work in another Region"))
```
We can see that by average North America and Europe are close, while the rest are much lower, especially Asia.
The regions that do not appear, don't employ remote workers from another regions.

In relation to the high paying, we can see that USA pays less for remote work, than for office work. On the other hand in Europe the salary is on the same level for remote and office work.

Now we can focus on answering the question. 

```{r}
aux <- data.frame(matrix(0, nrow = length(levels(df$company_region)), ncol = length(levels(df$company_region))))
colnames(aux) <- levels(df$company_region)
rownames(aux) <- levels(df$company_region)

for (i in 1:nrow(aux)) {
  max = 0
  for (j in 1:ncol(aux)) {
    df_filtered <- filter(df, company_region == colnames(aux)[j] & employee_region == rownames(aux)[i])
    aux[i, j] <- mean(df_filtered$salary_in_usd)
  }
}

aux_clean <- data.frame(matrix(0, nrow = length(levels(df$company_region)), ncol = length(levels(df$company_region))))
colnames(aux_clean) <- levels(df$company_region)
rownames(aux_clean) <- levels(df$company_region)

aux <- replace(aux, is.na(aux), 0)

for (i in 1:nrow(aux_clean)) {
  max <- 0
  for (j in 1:ncol(aux_clean)) {
    #if(i == j) {
     # aux_clean[i,j] <- aux[i,j]
    #} else 
    if(aux[i,j]>max){
      max <- aux[i,j]
      aux_clean[i,j] <- aux[i,j]
    }
  }
}


data_long <- aux_clean %>%
  rownames_to_column %>%
  gather(key = 'key', value = 'value', -rowname) %>%
  filter(value > 0)
colnames(data_long) <- c("source", "target", "value")
data_long$target <- paste(data_long$target, " ", sep="")

nodes <- data.frame(name=c(as.character(data_long$source), as.character(data_long$target)) %>% unique())
 
data_long$IDsource=match(data_long$source, nodes$name)-1 
data_long$IDtarget=match(data_long$target, nodes$name)-1

sankeyNetwork(Links = data_long, Nodes = nodes,
                     Source = "IDsource", Target = "IDtarget",
                     Value = "value", NodeID = "name", 
                     sinksRight=FALSE, nodeWidth=40, fontSize=13, nodePadding=20)
```
In the plot above we can see on the left the employee region and on the right the company region where is more worth to work for them. 
The dataset is pretty unbalanced in general, some regions have very few entries and many of them are not representative compared to the rest of the data or other regions.

So we can conclude that with the current data is not possible to give a sensible answer for all of the regions and we would need to expand the dataset and balance the different regions and remote types.


### 3. Can the salary increase between 2021 and 2022 be explained by inflation?

```{r}
increase = (mean(df[df$work_year == 2022, 'salary_in_usd'])/mean(df[df$work_year == 2021, 'salary_in_usd'])) - 1
net_increase = increase - 0.077 # official inflation rate in 2022 in the US
net_increase
```

It seems like the increase in salaries between 2021 and 2022 is not explained only with the inflation, since the increase has been of over a 34% in total and the official 2022 inflation rate that the US government gives is ay 7.7%. The net salary increase taking that into account (most samples of the data are US based), net salaries have increased a 27.17%.


### 4. Join cost of living index dataset into problem dataset

We only want the country and the cost of living and we delete Kosovo from the list since it is a disputed territory and luckily enough we don't have any Kosovo related data in our dataset
```{r}
cost_of_living_df = read.csv("Cost_of_Living_Index_2022.csv", stringsAsFactors = TRUE)[-67, c(2,3)]
cost_of_living_df = setNames(cost_of_living_df, c("country", "cost_of_living_index"))
cost_of_living_df$country = countrycode(cost_of_living_df$country, origin = 'country.name', destination = 'iso2c')
```

Add the cost of living index columns of the employee residence and the company location deleting those rows that contain either American Samoa or Aaland Islands, since we don't have information about the cost of living index in these countries.

```{r}
dfN<-subset(df, employee_residence!="AX" & employee_residence!="AS" & company_location!="AX" & company_location!="AS")
dfN$cost_of_living_index_employee = rep(0, nrow(dfN))
dfN$cost_of_living_index_company = rep(0, nrow(dfN))
for(i in 1:nrow(dfN)) {
  country_employee = dfN[i, ]$employee_residence
  country_company = dfN[i, ]$company_location
  index_employee =  cost_of_living_df[as.character(cost_of_living_df$country)==as.character(country_employee), ]$cost_of_living_index
  index_company = cost_of_living_df[as.character(cost_of_living_df$country)==as.character(country_company), ]$cost_of_living_index
  dfN[i,]$cost_of_living_index_employee = index_employee
  dfN[i,]$cost_of_living_index_company = index_company
}
```

Let's find the employees that live in a cheaper country than the one that they work for.

```{r}
subset(dfN, cost_of_living_index_employee>cost_of_living_index_company)
subset(dfN, as.character(company_location)!=as.character(employee_residence))
```
